{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a326d9",
   "metadata": {},
   "source": [
    "# Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c8e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import inception_v3\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d778119",
   "metadata": {},
   "source": [
    "# Defining the models and other functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1106c9",
   "metadata": {},
   "source": [
    "### For VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60466907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 23s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model1 = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features1(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = vgg16.preprocess_input(img_data)\n",
    "    features = model1.predict(img_data)\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb875f",
   "metadata": {},
   "source": [
    "### For ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147b43d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 41s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model2 = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e57db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features2(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = resnet50.preprocess_input(img_data)\n",
    "    features = model2.predict(img_data)\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee9a55",
   "metadata": {},
   "source": [
    "### For Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032f7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 30s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model3 = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features1(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = inception_v3.preprocess_input(img_data)\n",
    "    features = model3.predict(img_data)\n",
    "    return features.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5da06e",
   "metadata": {},
   "source": [
    "### Function to find similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_images(input_image_features):\n",
    "    similarities = [cosine_similarity([input_image_features], [features])[0][0] for features in image_features]\n",
    "    sorted_indices = np.argsort(similarities)[::-1][:5]  # Get indices of top 5 similar images\n",
    "    return [image_paths[index] for index in sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c7bfa",
   "metadata": {},
   "source": [
    "# Importing the dataset and extracting its features (1st 10000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:/Work/My work/Internships/AI_ML SME internship/Image reccomendation/archive/images\"\n",
    "\n",
    "image_features1 = []\n",
    "image_features2 = []\n",
    "image_features3 = []\n",
    "image_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if c<=10000:\n",
    "        current_image_path = os.path.join(dataset_old, filename)\n",
    "        image_paths.append(current_img_path)\n",
    "        image_features1.append(extract_features1(current_img_path))\n",
    "        image_features2.append(extract_features2(current_img_path))\n",
    "        image_features3.append(extract_features3(current_img_path))\n",
    "        c = c+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566c0f8",
   "metadata": {},
   "source": [
    "# Selecting a random image and generating its top 5 similar images for all 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = random.choice(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b0687",
   "metadata": {},
   "source": [
    "### For VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_features1 = extract_features1(random_image_path)\n",
    "list_similar_images1 = similar_images(input_image_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, img_path in enumerate([random_image_path] + list_similar_images1, 1):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Similar Image {i-1}\" if i > 1 else \"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473edbe4",
   "metadata": {},
   "source": [
    "### For ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a32470",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_features2 = extract_features2(random_image_path)\n",
    "list_similar_images2 = similar_images(input_image_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61351c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, img_path in enumerate([random_image_path] + list_similar_images2, 1):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Similar Image {i-1}\" if i > 1 else \"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd01f5a",
   "metadata": {},
   "source": [
    "### For Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_features3 = extract_features3(random_image_path)\n",
    "list_similar_images3 = similar_images(input_image_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, img_path in enumerate([random_image_path] + list_similar_images3, 1):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Similar Image {i-1}\" if i > 1 else \"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
